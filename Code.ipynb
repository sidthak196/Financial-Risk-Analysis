{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.graphics.tsaplots as tsplot\n",
    "import arch as arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Stock and Index price database \n",
    "st_date = dt.datetime(2019,1,1)\n",
    "en_date = dt.datetime(2022,2,28)\n",
    "stks_needed = ['JPM', 'SPY']#^GSPC\n",
    "Stk_prices_list = []\n",
    "flag = 0\n",
    "for tc in list(stks_needed):\n",
    "    if flag ==0 : \n",
    "        flag =1 \n",
    "        Stk_prices_list.append(pdr.DataReader(tc, 'yahoo', start=st_date, end=en_date)['Adj Close'].index)\n",
    "    Stk_prices_list.append(pdr.DataReader(tc, 'yahoo', start=st_date, end=en_date)['Adj Close'].tolist())\n",
    "\n",
    "#Create Database of stock prices\n",
    "dataframe = pd.DataFrame(list(map(list, zip(*Stk_prices_list))),columns=['Date','JPM','SPY'])\n",
    "# dataframe.to_csv(\"Adjusted_close_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data and Build Up Risk Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: 3149.429427588736\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: 972.9377305783098\n",
      "Iteration:      3,   Func. Count:     20,   Neg. LLF: 3053.7654373356795\n",
      "Iteration:      4,   Func. Count:     26,   Neg. LLF: 260.9790241598004\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: 260.97760493194795\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: 260.97760343516813\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: 260.977603435294\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 260.97760343516813\n",
      "            Iterations: 7\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: 544.6370656989527\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: 673.5658371925069\n",
      "Iteration:      3,   Func. Count:     20,   Neg. LLF: 0.8625650307839692\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -296.3613973484566\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -297.67088730247895\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -297.6790099035467\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -297.67907022779735\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -297.6790835019724\n",
      "Iteration:      9,   Func. Count:     45,   Neg. LLF: -297.6790835024081\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -297.6790835019724\n",
      "            Iterations: 9\n",
      "            Function evaluations: 45\n",
      "            Gradient evaluations: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.06058. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Scalar = 100\n",
    "# Estimate both your symbol and SPY (independently) log return volatility using GARCH (1,1) from data Jan 1, 2019 to Dec 31, 2021\n",
    "dataframe[\"JPM_Log_returns\"] = [np.log(i) for i in dataframe[\"JPM\"]]\n",
    "dataframe[\"JPM_Log_returns\"]=dataframe[\"JPM_Log_returns\"].pct_change()*Scalar\n",
    "dataframe[\"SPY_Log_returns\"] = [np.log(i) for i in dataframe[\"SPY\"]]\n",
    "dataframe[\"SPY_Log_returns\"]=dataframe[\"SPY_Log_returns\"].pct_change()*Scalar\n",
    "\n",
    "Vol_JPM = np.std(dataframe['JPM_Log_returns'])\n",
    "Vol_SPY = np.std(dataframe['SPY_Log_returns'])\n",
    "\n",
    "#Check plots for Log returns \n",
    "# plt.plot(dataframe['JPM_Log_returns'])\n",
    "# plt.title(\"JPM Log Returns\")\n",
    "# plt.xlabel(\"Time units\")\n",
    "# plt.ylabel(\"Log Returns\")\n",
    "# plt.show()\n",
    "# # print(np.mean(dataframe['JPM_Log_returns']))\n",
    "# plt.plot(dataframe['SPY_Log_returns'])\n",
    "# plt.title(\"SPY Log Returns\")\n",
    "# plt.xlabel(\"Time units\")\n",
    "# plt.ylabel(\"Log Returns\")\n",
    "# plt.show()\n",
    "# #HISTOGRAM\n",
    "# plt.hist(dataframe['JPM_Log_returns'])\n",
    "# plt.title(\"JPM Log Returns\")\n",
    "# plt.xlabel(\"Returns\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n",
    "# # print(np.mean(dataframe['JPM_Log_returns']))\n",
    "# plt.hist(dataframe['SPY_Log_returns'])\n",
    "# plt.title(\"SPY Log Returns\")\n",
    "# plt.xlabel(\"Returns\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n",
    "# print(np.mean(dataframe['SPY_Log_returns']))\n",
    "# tsplot.plot_acf(dataframe['JPM_Log_returns'][1:])\n",
    "# plt.show()\n",
    "# tsplot.plot_acf(dataframe['SPY_Log_returns'][1:])\n",
    "# plt.show()\n",
    "# tsplot.plot_pacf(dataframe['JPM_Log_returns'][1:])\n",
    "# plt.show()\n",
    "# tsplot.plot_pacf(dataframe['SPY_Log_returns'][1:])\n",
    "# plt.show()\n",
    "\n",
    "#Get Train data based on date\n",
    "Train_end_date = dt.datetime(2021,12,31)\n",
    "Train_data = dataframe.loc[dataframe['Date']<=Train_end_date]\n",
    "Test_data = dataframe.loc[dataframe['Date']>Train_end_date]\n",
    "Total_len = len(dataframe) \n",
    "Test_len = Total_len -len(Train_data)\n",
    "\n",
    "\n",
    "#Fit Garch(1,1) model to data\n",
    "JPM_Garch_model = arch.arch_model(Train_data[\"JPM_Log_returns\"][1:],mean=\"Zero\",vol='GARCH',p=1,q=1).fit()\n",
    "SPY_Garch_model = arch.arch_model(Train_data[\"SPY_Log_returns\"][1:],mean=\"Zero\",vol='GARCH',p=1,q=1).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:        JPM_Log_returns   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.001\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -260.978\n",
      "Distribution:                  Normal   AIC:                           527.955\n",
      "Method:            Maximum Likelihood   BIC:                           541.839\n",
      "                                        No. Observations:                  756\n",
      "Date:                Sun, Apr 10 2022   Df Residuals:                      756\n",
      "Time:                        19:29:05   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      6.0045e-03  2.385e-03      2.517  1.183e-02 [1.329e-03,1.068e-02]\n",
      "alpha[1]       0.1896  6.231e-02      3.043  2.340e-03   [6.751e-02,  0.312]\n",
      "beta[1]        0.7774  5.945e-02     13.077  4.474e-39     [  0.661,  0.894]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "#Model Statistics\n",
    "print(JPM_Garch_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:        SPY_Log_returns   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.001\n",
      "Vol Model:                      GARCH   Log-Likelihood:                297.679\n",
      "Distribution:                  Normal   AIC:                          -589.358\n",
      "Method:            Maximum Likelihood   BIC:                          -575.474\n",
      "                                        No. Observations:                  756\n",
      "Date:                Sun, Apr 10 2022   Df Residuals:                      756\n",
      "Time:                        19:29:05   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      1.8954e-03  5.993e-04      3.163  1.562e-03 [7.209e-04,3.070e-03]\n",
      "alpha[1]       0.2578  5.876e-02      4.388  1.142e-05     [  0.143,  0.373]\n",
      "beta[1]        0.7045  4.824e-02     14.606  2.575e-48     [  0.610,  0.799]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "print(SPY_Garch_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecast Garch Values Function - Not needed for the Project \n",
    "def Garch_Var(n, omega , alpha , beta, last_value, last_pct):\n",
    "    vols = [last_value]*(n+1)\n",
    "    returns = [last_pct]*(n+1)\n",
    "    for i in range(1,n+1):\n",
    "        vols[i] = (omega + (alpha * (returns[i-1]**2)) + (beta * vols[i-1]**2))**0.5\n",
    "        returns[i] = vols[i] * np.random.normal(0,1)/Scalar # Assumung returns have mean 0 and volatility is coming from GARCH model\n",
    "    return vols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          h.1\n",
      "756  0.205546\n",
      "          h.1\n",
      "756  0.123926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\arch\\__future__\\_utility.py:11: FutureWarning: \n",
      "The default for reindex is True. After September 2021 this will change to\n",
      "False. Set reindex to True or False to silence this message. Alternatively,\n",
      "you can use the import comment\n",
      "\n",
      "from arch.__future__ import reindexing\n",
      "\n",
      "to globally set reindex to True and silence this warning.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\arch\\__future__\\_utility.py:11: FutureWarning: \n",
      "The default for reindex is True. After September 2021 this will change to\n",
      "False. Set reindex to True or False to silence this message. Alternatively,\n",
      "you can use the import comment\n",
      "\n",
      "from arch.__future__ import reindexing\n",
      "\n",
      "to globally set reindex to True and silence this warning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Get Volatility Estimates from the model results for period Dec 31st 2021 to Feb 28 2022\n",
    "Jpm_return_estimates = Garch_Var(Test_len, JPM_Garch_model.params[0],JPM_Garch_model.params[1],JPM_Garch_model.params[2],np.std(Train_data[\"JPM_Log_returns\"][1:]), Test_data[\"JPM_Log_returns\"].reset_index(drop=True)[0])\n",
    "# plt.plot([i for i in Jpm_return_estimates])# in Percentages\n",
    "# plt.plot(Test_data[\"JPM_Log_returns\"].reset_index(drop=True))\n",
    "# plt.show()\n",
    "# print(Jpm_return_estimates[1])\n",
    "print(JPM_Garch_model.forecast(horizon=1).variance[-1:]**0.5)\n",
    "\n",
    "Spy_return_estimates = Garch_Var(Test_len, SPY_Garch_model.params[0],SPY_Garch_model.params[1],SPY_Garch_model.params[2],np.std(Train_data[\"SPY_Log_returns\"][1:]), Test_data[\"SPY_Log_returns\"].reset_index(drop=True)[0]/100)\n",
    "# plt.plot([i*100 for i in Spy_return_estimates])\n",
    "# plt.plot(Test_data[\"SPY_Log_returns\"].reset_index(drop=True))\n",
    "# plt.show()\n",
    "# print(Spy_return_estimates[1])\n",
    "print(SPY_Garch_model.forecast(horizon=1).variance[-1:]**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation estimate for actual returns (TRAIN Data):  0.7765645219986756\n",
      "Correlation estimate for estmated returns:  0.976520127312045\n",
      "Correlation estimate for test returns (TEST DATA):  0.42715098370511295\n",
      "Correlation estimate for test returns (FULL DATA):  0.7648478335346234\n"
     ]
    }
   ],
   "source": [
    "#Correlation for Actual Data\n",
    "Corr_actual = np.corrcoef(Train_data['JPM_Log_returns'][1:], Train_data['SPY_Log_returns'][1:])\n",
    "print(\"Correlation estimate for actual returns (TRAIN Data): \",Corr_actual[0,1])\n",
    "\n",
    "#Correlation for Estimated Data\n",
    "Corr_Estimated = np.corrcoef(Jpm_return_estimates, Spy_return_estimates)\n",
    "print(\"Correlation estimate for estmated returns: \",Corr_Estimated[0,1])\n",
    "\n",
    "\n",
    "#Correlation for test Data\n",
    "Corr_test = np.corrcoef(Test_data['JPM_Log_returns'], Test_data['SPY_Log_returns'])\n",
    "print(\"Correlation estimate for test returns (TEST DATA): \",Corr_test[0,1])\n",
    "\n",
    "#Model does not perform so well\n",
    "\n",
    "#Correlation for Full Data\n",
    "Corr_test = np.corrcoef(dataframe['JPM_Log_returns'][1:], dataframe['SPY_Log_returns'][1:])\n",
    "print(\"Correlation estimate for test returns (FULL DATA): \",Corr_test[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inital Asset Value \n",
    "Inv_Value_A = 1000000\n",
    "Inv_Value_B = 1000000\n",
    "Inv_Value_C = 2000000\n",
    "\n",
    "#VaR percentile\n",
    "VaR_Conf = 0.99\n",
    "temp_percentile_99 = (Total_len - Test_len)*(1-VaR_Conf)\n",
    "perc_99 = int(temp_percentile_99)\n",
    "perc_weight = temp_percentile_99 - perc_99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VaR Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one day 99% Var and ES for JPM:  -62327.298363982336 -104580.93013463018\n",
      "one day 99% Var and ES for SPY:  -44964.90286477064 -73370.9909039779\n",
      "one day 99% Var and ES for the Portfolio:  -98786.35572423699 -175951.2612215544\n"
     ]
    }
   ],
   "source": [
    "JPM_Hist_Sim = [i*Inv_Value_A for i in dataframe[\"JPM\"].pct_change()[1:]]\n",
    "JPM_Hist_Sim_Sort = JPM_Hist_Sim[:]\n",
    "JPM_Hist_Sim_Sort.sort()\n",
    "JPM_VaR = perc_weight * JPM_Hist_Sim_Sort[perc_99 - 1] + (1-perc_weight) * JPM_Hist_Sim_Sort[perc_99]\n",
    "JPM_ES = np.mean(JPM_Hist_Sim_Sort[0:perc_99-1])\n",
    "print(\"one day 99% Var and ES for JPM: \",JPM_VaR, JPM_ES)\n",
    "\n",
    "SPY_Hist_Sim = [i*Inv_Value_A for i in dataframe[\"SPY\"].pct_change()[1:]]\n",
    "SPY_Hist_Sim_Sort=SPY_Hist_Sim[:]\n",
    "SPY_Hist_Sim_Sort.sort()\n",
    "SPY_VaR = perc_weight * SPY_Hist_Sim_Sort[perc_99 - 1] + (1-perc_weight) * SPY_Hist_Sim_Sort[perc_99]\n",
    "SPY_ES = np.mean(SPY_Hist_Sim_Sort[0:perc_99-1])\n",
    "print(\"one day 99% Var and ES for SPY: \",SPY_VaR, SPY_ES)\n",
    "\n",
    "Port_Hist_Sim = [(SPY_Hist_Sim[i]+JPM_Hist_Sim[i]) for i in range(len(SPY_Hist_Sim))]\n",
    "Port_Hist_Sim_Sort=Port_Hist_Sim[:]\n",
    "Port_Hist_Sim_Sort.sort()\n",
    "Port_VaR = perc_weight * Port_Hist_Sim_Sort[perc_99 - 1] + (1-perc_weight) * Port_Hist_Sim_Sort[perc_99]\n",
    "Port_ES = np.mean(Port_Hist_Sim_Sort[0:perc_99-1])\n",
    "print(\"one day 99% Var and ES for the Portfolio: \",Port_VaR, Port_ES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceptions incurred in backtesting:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "#BackTesting \n",
    "BackTesting_Start_date = dt.datetime(2021,3,1)\n",
    "Backtest_data = dataframe.loc[dataframe['Date']>= BackTesting_Start_date,\"JPM\"]\n",
    "\n",
    "Backtest_data = [i*Inv_Value_A for i in  Backtest_data.pct_change()[1:]]\n",
    "\n",
    "Exceptions = [i for i in Backtest_data if i<=JPM_VaR]\n",
    "[min(Backtest_data),JPM_VaR]\n",
    "print(\"Exceptions incurred in backtesting: \",len(Exceptions)/Total_len*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000815878220583063 0.022186212231809537\n",
      "0.0008597313060295603 0.013760551338635348\n"
     ]
    }
   ],
   "source": [
    "JPM_Mean = np.mean(dataframe[\"JPM\"].pct_change()[1:])\n",
    "JPM_std = np.std(dataframe[\"JPM\"].pct_change()[1:])\n",
    "print(JPM_Mean, JPM_std)\n",
    "SPY_Mean = np.mean(dataframe[\"SPY\"].pct_change()[1:])\n",
    "SPY_std = np.std(dataframe[\"SPY\"].pct_change()[1:])\n",
    "print(SPY_Mean, SPY_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>JPM</th>\n",
       "      <th>SPY</th>\n",
       "      <th>JPM_Log_returns</th>\n",
       "      <th>SPY_Log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>156.248322</td>\n",
       "      <td>473.489044</td>\n",
       "      <td>-0.016242</td>\n",
       "      <td>-0.040946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>159.553833</td>\n",
       "      <td>476.230530</td>\n",
       "      <td>0.414432</td>\n",
       "      <td>0.093720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         JPM         SPY  JPM_Log_returns  SPY_Log_returns\n",
       "756 2021-12-31  156.248322  473.489044        -0.016242        -0.040946\n",
       "757 2022-01-03  159.553833  476.230530         0.414432         0.093720"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JPM_ret_0104 = Test_data\n",
    "(dataframe.iloc[756:758])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08abd7b7c8d0be127d4e4a7867fced7f62c6dcfa7739a0184e3b4f48aa7caea7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
